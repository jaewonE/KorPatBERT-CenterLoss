{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 11:30:02.433441: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 29 11:30:03 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A5000               Off |   00000000:01:00.0 Off |                  Off |\n",
      "| 31%   53C    P0             87W /  230W |     239MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1336      G   /usr/lib/xorg/Xorg                            215MiB |\n",
      "|    0   N/A  N/A      1544      G   /usr/bin/gnome-shell                            8MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from korpat_tokenizer import Tokenizer  # Ensure this file is available\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_path_train = '/home/billy/rd/dataset/DS학술제-모델링경진대회_Train.xlsx'\n",
    "xlsx_path_test = '/home/billy/rd/dataset/DS학술제-모델링경진대회_Valid.xlsx'\n",
    "\n",
    "config_path = \"./pretrained/korpat_bert_config.json\"  # KorPatBert 설정 파일 경로\n",
    "vocab_path = \"./pretrained/korpat_vocab.txt\"         # KorPatTokenizer 어휘 사전 파일 경로\n",
    "checkpoint_path = \"./pretrained/model.ckpt-381250\"        # KorPatBert 모델 체크포인트 경로\n",
    "pretrained_model_dir = \"./pretrained/\"                    # KorPatBert 모델 디렉토리\n",
    "save_model_path = \"./korpat_bert_test_model.h5\"           # 학습된 모델을 저장할 경로\n",
    "\n",
    "# 학습 파라미터\n",
    "MAX_SEQ_LEN = 256\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 5\n",
    "LR = 0.00003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 인코딩 결과:\n",
      "G06F: 0\n",
      "G06Q: 1\n",
      "G16H: 2\n",
      "레이블 클래스 수: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def load_data(data_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_excel(data_path,\n",
    "                       usecols=['발명의 명칭', '요약', '메인IPC2', '대표청구항'])\n",
    "    df['input'] = df.apply(\n",
    "        lambda row: f\"{row['발명의 명칭']}\\n\\n{row['요약']}\", axis=1)\n",
    "    df = df.drop(columns=['발명의 명칭', '요약', '대표청구항'])\n",
    "    df.columns = ['메인IPC2', '대표청구항']\n",
    "    return df\n",
    "\n",
    "\n",
    "# 토크나이저 설정\n",
    "tokenizer = Tokenizer(vocab_path=vocab_path, cased=True)\n",
    "\n",
    "# 엑셀 파일에서 데이터 로드\n",
    "df_train = load_data(xlsx_path_train)\n",
    "df_test = load_data(xlsx_path_test)\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['label'] = label_encoder.fit_transform(df_train['메인IPC2'])\n",
    "\n",
    "# 레이블 인코딩 결과 출력\n",
    "print(\"레이블 인코딩 결과:\")\n",
    "for label, index in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)):\n",
    "    print(f\"{label}: {index}\")\n",
    "\n",
    "# 테스트 데이터의 보이지 않는 레이블 처리\n",
    "unseen_labels = set(df_test['메인IPC2']) - set(label_encoder.classes_)\n",
    "if unseen_labels:\n",
    "    print(\"주의: 테스트 데이터셋에 훈련 데이터셋에 없는 레이블이 있습니다. 해당 샘플을 제거합니다.\")\n",
    "    print(f\"제거될 레이블: {unseen_labels}\")\n",
    "    df_test = df_test[~df_test['메인IPC2'].isin(\n",
    "        unseen_labels)].reset_index(drop=True)\n",
    "\n",
    "# 테스트 레이블 변환\n",
    "df_test['label'] = label_encoder.transform(df_test['메인IPC2'])\n",
    "\n",
    "# 학습 데이터를 학습 세트와 검증 세트로 분할\n",
    "train_texts_full = df_train['대표청구항']\n",
    "train_labels_full = df_train['label']\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts_full, train_labels_full, test_size=0.1, random_state=42, stratify=train_labels_full\n",
    ")\n",
    "\n",
    "test_texts = df_test['대표청구항']\n",
    "test_labels = df_test['label']\n",
    "\n",
    "# 학습, 검증 및 테스트 데이터를 위한 DataFrame 생성\n",
    "train_data = pd.DataFrame({'sentence': train_texts, 'label': train_labels})\n",
    "val_data = pd.DataFrame({'sentence': val_texts, 'label': val_labels})\n",
    "test_data = pd.DataFrame({'sentence': test_texts, 'label': test_labels})\n",
    "\n",
    "# 클래스 수\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(\"레이블 클래스 수:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> 학습데이터 전처리 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "데이터 전처리 진행중: 2163it [00:13, 161.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> 전처리 결과 출력:\n",
      "===> tokens sample: ['[CLS]', '[', '청구', '항', '1', ']', '사용', '자', '의', '모바일', '단말기', '및', '상점', '의', 'POS', '단말기', '와', '연동', '된', '커', '##머스', '서버', '에서', '모바일', '커', '##머스', '서비스', '를', '제공', '하', '는', '방법', '에', '있', '어서', ',', '통신', '네트워크', '를', '통하', '여', '모바일', '커', '##머스', '에', '관련', '된', '[UNK]', '데이터', '를', '수집', '하', '는', '단계', ';', '수집', '된', '[UNK]', '데이터', '로부터', '만족', '도', '및', '영향', '##력', '을', '분석', '하', '여', '상점', '또는', '상품', '에', '대한', '랭킹', '정보', '를', '생성', '하', '는', '단계', ';', '상기', '랭킹', '정보', '를', '사용', '자', '의', '모바일', '단말기', '로', '제공', '하', '는', '단계', ';', '상기', '사용', '자', '의', '모바일', '단말기', '로부터', '구매', '하', '고자', '하', '는', '상품', '및', '상점', '정보', '를', '포함', '하', '는', '구매', '요청', '을', '수신', '하', '는', '단계', ';', '상기', '구매', '요청', '에', '따라', '모바일', '상품권', '또는', '주문', '정보', '를', '사용', '자', '의', '모바일', '단말기', '로', '전송', '하', '는', '단계', ';', '및', '상기', '모바일', '상품권', '또는', '주문', '정보', '가', '사용', '된', '상점', '을', '대상', '으로', '정산', '을', '진행', '하', '는', '단계', '를', '포함', '하', '는', '모바일', '커', '##머스', '서비스', '방법', '.', '[SEP]']\n",
      "===> indices sample: [5, 513, 921, 131, 19, 364, 84, 107, 9, 1374, 548, 44, 12010, 9, 10043, 548, 47, 2241, 30, 341, 18890, 533, 42, 1374, 341, 18890, 572, 16, 192, 12, 11, 157, 10, 25, 125, 8, 382, 687, 16, 791, 40, 1374, 341, 18890, 10, 669, 30, 4, 162, 16, 1631, 12, 11, 155, 126, 1631, 30, 4, 162, 176, 2275, 27, 44, 1533, 20427, 15, 757, 12, 40, 12010, 71, 1316, 10, 241, 14864, 142, 16, 307, 12, 11, 155, 126, 23, 14864, 142, 16, 84, 107, 9, 1374, 548, 37, 192, 12, 11, 155, 126, 23, 84, 107, 9, 1374, 548, 176, 2287, 12, 1295, 12, 11, 1316, 44, 12010, 142, 16, 79, 12, 11, 2287, 851, 15, 288, 12, 11, 155, 126, 23, 2287, 851, 10, 143, 1374, 8591, 71, 4062, 142, 16, 84, 107, 9, 1374, 548, 37, 336, 12, 11, 155, 126, 44, 23, 1374, 8591, 71, 4062, 142, 22, 84, 30, 12010, 15, 930, 33, 9448, 15, 1008, 12, 11, 155, 16, 79, 12, 11, 1374, 341, 18890, 572, 157, 14, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "===> x_data shape: (2163, 256)\n",
      "===> y_data shape: (2163, 3)\n",
      "\n",
      "===> 검증데이터 전처리 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "데이터 전처리 진행중: 241it [00:01, 151.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> 전처리 결과 출력:\n",
      "===> tokens sample: ['[CLS]', '[', '청구', '항', '1', ']', '회원', '사', '로부터', '회원', '아이디', ',', '사업자', '정보', ',', '매출', ',', '직원', '수', ',', '임', '##금', '정보', '를', '주기', '적', '으로', '수신', '하', '여', '회원', '사', '정보', 'DB', '에', '저장', '및', '관리', '하', '는', '[UNK]', '데이터', '관리', '부', ';', '회원', '사', '로부터', '노', '##무', '분석', '요청', '을', '수신', '하', '는', '노', '##무', '분석', '접', '##수부', ';', '상기', '회원', '사', '정보', 'DB', '에', '저장', '된', '사업자', '정보', '중', '업', '##태', '와', '종목', ',', '매출', '증감', '정도', ',', '직원', '수', '변화', ',', '임', '##금', '상승', '정도', '를', '기계', '학습', '(', 'Machine', 'L', '##ear', '##ning', ')', '하', '여', '업', '##태', '와', '종목', ',', '매출', ',', '직원', '수', ',', '임', '##금', '정보', '에', '따라', '신규', '직원', '채용', '을', '언제', '하', '면', '되', '는지', '또는', '기존', '직원', '의', '임', '##금', '을', '어느', '정도', '로', '인상', '하', '면', '되', '는지', '를', '추론', '하', '는', '노', '##무', '관리', '모델', '을', '생성', '하', '는', '노', '##무', '관리', '모델', '생', '성', '##부', '-', '입력', '변수', '에', '해당', '하', '는', '업', '##태', '와', '종목', ',', '매출', '증감', '정도', ',', '직원', '수', '변화', ',', '임', '##금', '상승', '정도', '를', '기계', '학습', '하', '면', '같', '은', '업', '##태', '와', '종목', '이', '라도', '매출', ',', '직원', '수', ',', '임', '##금', '수준', '에', '따라', '향후', '회사', '의', '성장', '을', '위해', '신규', '직원', '을', '언제', '채용', '해야', '하', '는지', ',', '아니', '##면', '기존', '직원', '의', '임', '##금', '을', '얼마나', '인상', '하', '는', '게', '좋', '은지', '를', '추론', '하', '는', '노', '##무', '관리', '모델', '을', '생', '성', '##함', '-', ';', '및', '상기', '노', '##무', '분석', '접', '##수부', '가', '접수', '한', '회', '원사', '에', '대한', '정보', '를', '상기', '회원', '사', '정보', 'DB', '에서', '검색', '후', '검색', '된', '업', '##태', '와', '종목', ',', '매출', '정보', ',', '직원', '수', ',', '임', '##금', '정보', '를', '상기', '노', '##무', '관리', '모델', '에', '적용', '하', '여', '노', '##무', '분석', '을', '요청', '한', '업체', '에', '적합', '한', '신규', '직원', '채용', '시기', '또는', '기존', '직원', '의', '임', '##금', '을', '얼마나', '인상', '해', '[UNK]', '##야', '하', '는지', '에', '대한', '정보', '를', '제공', '하', '는', '노', '##무', '분석', '제', '공부', '를', '포함', '하', '되', ',', '상기', '[UNK]', '데이터', '관리', '부', '는', '업종', '별', '경기', '실', '##사', '지수', '를', '경기', '지수', 'DB', '에', '저장', '및', '관리', '하', '고', ',', '상기', '노', '##무', '관리', '모델', '생', '성', '##부', '는', '경기', '지수', 'DB', '의', '업종', '별', '경기', '실', '##사', '지수', '를', '기계', '학습', '알고리즘', '에', '추가', '로', '반영', '하', '여', '업', '##태', '와', '종목', ',', '매출', '증감', '정도', ',', '해당', '업종', '별', '경기', '실', '##사', '지수', '에', '따라', '신규', '직원', '채용', '을', '언제', '하', '면', '되', '는지', '그리고', '기존', '직원', '의', '임', '##금', '을', '어느', '정도', '로', '인상', '하', '면', '되', '는지', '를', '추론', '하', '는', '노', '##무', '관리', '모델', '을', '생성', '하', '며', ',', '상기', '노', '##무', '관리', '모델', '은', '업종', '이', '다른', '업체', '가', '같', '은', '수준', '의', '매출', '증가', '일', '##지라도', '해당', '업종', '의', '경기', '실', '##사', '지수', '에', '따라', '신규', '직원', '을', '채용', '하', '면', '되', '는지', ',', '아니', '##면', '기존', '직원', '의', '임', '##금', '을', '인상', '하', '면', '되', '는지', '와', '같이', '서로', '다른', '결과', '를', '추천', '할', '수', '있', '고', ',', '상기', '[UNK]', '데이터', '관리', '부', '는', '회원', '사', '대표', '의', '성', '##격', ',', '자기', '의', '사업', '에', '대한', '관심', '도', '및', '열', '##정', '정도', '를', '회원', '사', '정보', 'DB', '에', '저장', '및', '관리', '하', '고', ',', '상기', '노', '##무', '관리', '모델', '생', '성', '##부', '는', '회원', '사', '정보', 'DB', '의', '회원', '사', '대표', '의', '성', '##격', ',', '자기', '의', '사업', '에', '대한', '관심', '도', '및', '열', '##정', '정도', '를', '기계', '학습', '알고리즘', '에', '추가', '로', '반영', '하', '여', '업', '##태', '와', '종목', ',', '매출', '증감', '정도', ',', '대표', '의', '성', '##격', '및', '사업', '에', '대한', '관심', '도', '와', '열', '##정', '정도', '에', '따라', '신규', '직원', '채용', '을', '언제', '하', '면', '되', '는지', '또는', '기존', '직원', '의', '임', '##금', '을', '어느', '정도', '로', '인상', '하', '면', '되', '는지', '를', '추론', '하', '는', '노', '##무', '관리', '모델', '을', '생성', '하', '며', ',', '업종', '별', '대표', '##자', '의', '사업', '에', '대한', '관심', '도', '와', '열', '##정', '정도', '를', '수치', '화', '하', '여', '기록', '하', '고', ',', '이', '를', '바탕', '으로', '업종', '전체', '에서', '의', '대표', '##자', '의', '위치', '를', '수치', '화', '하', '여', '관심', '도', '및', '열', '##정', 'DB', '에', '기록', '하', '는', '대표', '##자', '성향', '파악', '부', '-', '대표', '##자', '의', '사업', '에', '대한', '관심', '도', '와', '열', '##정', '정도', '는', '각각', '소정', '의', '범위', '에', '해당', '하', '는', '점수', '로', '기록', '하', '며', ',', '관심', '도', '점수', '는', '높', '으나', '열', '##정', '점수', '는', '낮', '을', '수', '도', '있', '으며', ',', '관심', '도', '점수', '와', '열', '##정', '점수', '를', '종합', '하', '여', '평균', '을', '구하', '고', '대표', '##자', '의', '사업', '에', '대한', '관심', '도', '와', '열', '##정', '정도', '를', '수치', '화', '함', '-', ';', '및', '상기', '경기', '지수', 'DB', '에', '저장', '되', '는', '업종', '별', '경기', '실', '##사', '지수', '를', '분석', '하', '여', '경기', '실', '##사', '지수', '의', '변동', '률', '이', '전체', '업종', '대비', '일정', '수준', '이하', '인', '업종', '에', '대해서', '는', '상기', '대표', '##자', '성향', '파악', '부', '에서', '수치', '화', '하', '여', '기록', '한', '업종', '전체', '에서', '의', '대표', '##자', '의', '위치', '에', '따라', '가중치', '를', '다르', '게', '설정', '하', '는', '대표', '##자', '가중치', '설', '정부', '를', '더', '포함', '하', '고', ',', '상기', '노', '##무', '관리', '모델', '생', '성', '##부', '는', '경기', '지수', 'DB', '의', '업종', '별', '경기', '실', '##사', '지수', '와', '회원', '사', '정보', 'DB', '의', '회원', '사', '대표', '의', '성', '##격', ',', '자기', '의', '사업', '에', '대한', '관심', '도', '및', '열', '##정', '정도', '를', '기계', '학습', '알고리즘', '에', '추가', '로', '반영', '하', '여', '업', '##태', '와', '종목', ',', '매출', '증감', '정도', ',', '해당', '업종', '별', '경기', '실', '##사', '지수', '그리고', '대표', '의', '성', '##격', ',', '사업', '에', '대한', '관심', '도', '와', '열', '##정', '정도', '에', '따라', '신규', '직원', '채용', '을', '언제', '하', '면', '되', '는지', '또는', '기존', '직원', '의', '임', '##금', '을', '어느', '정도', '로', '인상', '하', '면', '되', '는지', '를', '추론', '하', '는', '노', '##무', '관리', '모델', '을', '생성', '하', '되', ',', '상기', '대표', '##자', '가중치', '설', '정부', '에서', '설정', '한', '가중치', '를', '반영', '하', '여', '노', '##무', '관리', '모델', '을', '생성', '하', '며', ',', '상기', '대표', '##자', '가중치', '설', '정부', '는', '경기', '실', '##사', '지수', '의', '변동', '률', '이', '전체', '업종', '대비', '하위', '에', '속하', '는', '정도', '로', '경기', '실', '##사', '지수', '변동', '이', '크', '지', '않', '은', '업종', '의', '경우', '해당', '업종', '에', '속하', '는', '업체', '대표', '##자', '의', '관심', '도', '와', '열', '##정', '이', '해당', '업종', '내', '에서', '상위', '제', '1', '비율', '에', '속하', '면', '제', '1', '가중치', '를', '곱하', '고', ',', '상위', '제', '2', '비율', '에', '속하', '면', '제', '2', '가중치', '를', '곱하', '고', ',', '상위', '제', '3', '비율', '에', '속하', '면', '제', '3', '가중치', '를', '곱하', '는', '방식', '(', '여기', '서', '제', '1', '비율', '<', '제', '2', '비율', '<', '제', '3', '비율', ',', '제', '1', '가중치', '>', '제', '2', '가중치', '>', '제', '3', '가중치', '순서', '임', ')', '으로', '대표', '##자', '의', '위치', '점수', '에', '따라', '가중치', '의', '차이', '를', '[UNK]', '으로써', ',', '경기', '실', '##사', '지수', '의', '변동', '이', '작', '은', '업종', '에서', '는', '대표', '##자', '의', '역', '##량', '이', '그만큼', '영향', '##력', '이', '크', '기', '때문', '에', '해당', '업종', '에서', '대표', '##자', '의', '위치', '를', '중요', '하', '게', '반영', '하', '는', '것', '을', '특징', '으로', '하', '는', '인공', '##지', '##능', '기반', '으로', '업종', '과', '매출', '분석', '을', '통해', '노', '##무', '관리', '서비스', '를', '제공', '하', '는', '시스템', '.', '[SEP]']\n",
      "===> indices sample: [5, 513, 921, 131, 19, 364, 2822, 50, 176, 2822, 6392, 8, 4092, 142, 8, 12428, 8, 11855, 24, 8, 361, 20546, 142, 16, 1524, 45, 33, 288, 12, 40, 2822, 50, 142, 2799, 10, 301, 44, 682, 12, 11, 4, 162, 682, 75, 126, 2822, 50, 176, 298, 20567, 757, 851, 15, 288, 12, 11, 298, 20567, 757, 158, 16931, 126, 23, 2822, 50, 142, 2799, 10, 301, 30, 4092, 142, 74, 1153, 20472, 47, 17429, 8, 12428, 9070, 950, 8, 11855, 24, 709, 8, 361, 20546, 1285, 950, 16, 1233, 2424, 35, 18544, 264, 7570, 11490, 31, 12, 40, 1153, 20472, 47, 17429, 8, 12428, 8, 11855, 24, 8, 361, 20546, 142, 10, 143, 3340, 11855, 3183, 15, 9569, 12, 81, 26, 1148, 71, 1661, 11855, 9, 361, 20546, 15, 525, 950, 37, 10703, 12, 81, 26, 1148, 16, 9186, 12, 11, 298, 20567, 682, 1626, 15, 307, 12, 11, 298, 20567, 682, 1626, 173, 106, 20311, 29, 294, 3228, 10, 648, 12, 11, 1153, 20472, 47, 17429, 8, 12428, 9070, 950, 8, 11855, 24, 709, 8, 361, 20546, 1285, 950, 16, 1233, 2424, 12, 81, 113, 32, 1153, 20472, 47, 17429, 13, 3906, 12428, 8, 11855, 24, 8, 361, 20546, 2025, 10, 143, 14597, 6874, 9, 1436, 15, 267, 3340, 11855, 15, 9569, 3183, 1604, 12, 1148, 8, 527, 20341, 1661, 11855, 9, 361, 20546, 15, 12170, 10703, 12, 11, 64, 1152, 15408, 16, 9186, 12, 11, 298, 20567, 682, 1626, 15, 173, 106, 20374, 29, 126, 44, 23, 298, 20567, 757, 6]\n",
      "===> x_data shape: (241, 256)\n",
      "===> y_data shape: (241, 3)\n",
      "\n",
      "===> 테스트데이터 전처리 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "데이터 전처리 진행중: 602it [00:04, 137.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> 전처리 결과 출력:\n",
      "===> tokens sample: ['[CLS]', '[', '청구', '항', '2', ']', '메인', '서버', '(', '20', ')', '는', '저장', '장치', '(', '30', ')', '에', '저장', '시킨', '[UNK]', '데', '이타', '를', '기초', '로', '정신', '및', '심리', '분석', '선정', '단어', ',', '색상', ',', '그림', ',', '특정', '행동', '등', '을', '샘플링', '하', '여', '저장', '하', '고', ',', '메인', '서버', '에서', '환자', '의', '투', '##병', '관련', '기록', '인', '종이', '시트', '나', '온라인', '상', '의', '플랫폼', '에서', '작성', '하', '거나', '오프라인', '상', '에서', '기록', '한', '워드', '파일', '이나', ',', '기록', '사진', '이나', '녹음', '파일', '이나', '영상', '파일', '등', '으로', '저장', '하', '고', ',', '저장', '파일', '을', '메인', '서버', '가', '텍스트', '파일', ',', '녹음', '파일', ',', '그림', '파일', '등', '으로', '구분', '하', '여', '변환', '한', '것', '을', '기초', '로', '우울증', '에', '해당', '하', '는', '인식', '단어', '나', '인식', '색상', '이나', '인식', '영상', '을', '차례', '로', '검색', '하', '는', '검색', '모듈', '(', '50', ')', ';', '검색', '모듈', '(', '50', ')', '에서', '검색', '단어', '나', '색상', '이나', '영상', '이', '있', '는지', '를', '순차', '선택', '하', '는', '멀티', '##플', '레', '##서', '(', '60', ')', ';', '멀티플렉서', '(', '60', ')', '에서', '선택', '한', '인식', '단어', '나', '인식', '색상', '이나', '인식', '영상', '등', '을', '메인', '서버', '에', '기', '저장', '한', '[UNK]', '데이터', '와', '비교', '판단', '하', '여', '저장', '하', '는', '판단', '모듈', '(', '70', ')', ';', '및', '판단', '모듈', '(', '70', ')', '에서', '판단', '한', '단어', '와', '색상', '과', '인식', '영상', '등', '을', '필드', '별', '로', '구분', '해', '저장', '하', '고', '횟수', '도', '저장', '하', '여', ',', '증', '##세', '정도', '를', '판단', '하', '도록', '메인', '서버', '(', '20', ')', '에', '제공', '하', '는', '저장', '장치', '(', '30', ')', '를', '포함', '하', '여', '구성', '한', '것', '이', '특징', '인', ',', '환자', '투', '##병', '관련', '기록', '을', '자동', '으로', '인식', '하', '여', '분석', '하', '는', '정신', '심리', '분석', '시스템', '.', '[SEP]']\n",
      "===> indices sample: [5, 513, 921, 131, 36, 364, 1184, 533, 35, 278, 31, 11, 301, 135, 35, 532, 31, 10, 301, 559, 4, 137, 16836, 16, 781, 37, 6824, 44, 13899, 757, 4298, 3691, 8, 2618, 8, 4802, 8, 544, 6544, 147, 15, 3336, 12, 40, 301, 12, 34, 8, 1184, 533, 42, 1645, 9, 327, 20769, 669, 705, 53, 3213, 795, 109, 3328, 17, 9, 3720, 42, 2981, 12, 335, 8478, 17, 42, 705, 21, 2614, 891, 668, 8, 705, 2305, 668, 7989, 891, 668, 494, 891, 147, 33, 301, 12, 34, 8, 301, 891, 15, 1184, 533, 22, 3111, 891, 8, 7989, 891, 8, 4802, 891, 147, 33, 2231, 12, 40, 620, 21, 56, 15, 781, 37, 19131, 10, 648, 12, 11, 1088, 3691, 109, 1088, 2618, 668, 1088, 494, 15, 4320, 37, 1147, 12, 11, 1147, 486, 35, 585, 31, 126, 1147, 486, 35, 585, 31, 42, 1147, 3691, 109, 2618, 668, 494, 13, 25, 1148, 16, 1808, 258, 12, 11, 1229, 20452, 346, 20310, 35, 892, 31, 126, 6963, 35, 892, 31, 42, 258, 21, 1088, 3691, 109, 1088, 2618, 668, 1088, 494, 147, 15, 1184, 533, 10, 38, 301, 21, 4, 162, 47, 519, 843, 12, 40, 301, 12, 11, 843, 486, 35, 1286, 31, 126, 44, 843, 486, 35, 1286, 31, 42, 843, 21, 3691, 47, 2618, 55, 1088, 494, 147, 15, 1526, 692, 37, 2231, 169, 301, 12, 34, 3556, 27, 301, 12, 40, 8, 243, 20418, 950, 16, 843, 12, 118, 1184, 533, 35, 278, 31, 10, 192, 12, 6]\n",
      "===> x_data shape: (602, 256)\n",
      "===> y_data shape: (602, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def preprocessing_dataset(dataset, num_classes):\n",
    "    tokens, indices, labels = [], [], []\n",
    "\n",
    "    for label, sentence in tqdm(zip(dataset['label'], dataset['sentence']), desc=\"데이터 전처리 진행중\"):\n",
    "        tokens.append(tokenizer.tokenize(sentence))\n",
    "        ids, _ = tokenizer.encode(sentence, max_len=MAX_SEQ_LEN)\n",
    "        indices.append(ids)\n",
    "        # 레이블을 원-핫 인코딩 벡터로 변환\n",
    "        labels.append(to_categorical(label, num_classes=num_classes))\n",
    "\n",
    "    x_data = np.array(indices)\n",
    "    y_data = np.array(labels)\n",
    "    print(\"===> 전처리 결과 출력:\")\n",
    "    print(\"===> tokens sample:\", tokens[0])\n",
    "    print(\"===> indices sample:\", indices[0])\n",
    "    print(\"===> x_data shape:\", x_data.shape)\n",
    "    print(\"===> y_data shape:\", y_data.shape)\n",
    "\n",
    "    return tokens, x_data, y_data\n",
    "\n",
    "\n",
    "print(\"===> 학습데이터 전처리 시작\")\n",
    "train_tokens, train_x, train_y = preprocessing_dataset(train_data, num_classes)\n",
    "\n",
    "print(\"\\n===> 검증데이터 전처리 시작\")\n",
    "val_tokens, val_x, val_y = preprocessing_dataset(val_data, num_classes)\n",
    "\n",
    "print(\"\\n===> 테스트데이터 전처리 시작\")\n",
    "test_tokens, test_x, test_y = preprocessing_dataset(test_data, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 11:30:23.590946: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2024-11-29 11:30:23.693626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-29 11:30:23.696757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA RTX A5000 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 64 deviceMemorySize: 23.58GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2024-11-29 11:30:23.696770: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-11-29 11:30:23.699129: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2024-11-29 11:30:23.699162: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-11-29 11:30:23.712321: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2024-11-29 11:30:23.712473: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2024-11-29 11:30:23.730068: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2024-11-29 11:30:23.730532: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-11-29 11:30:23.730632: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-11-29 11:30:23.730700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-29 11:30:23.733470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-29 11:30:23.736133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2024-11-29 11:30:23.736517: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-29 11:30:23.737239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-29 11:30:23.739991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA RTX A5000 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 64 deviceMemorySize: 23.58GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2024-11-29 11:30:23.740024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-29 11:30:23.742665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-29 11:30:23.745033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2024-11-29 11:30:23.745050: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-11-29 11:30:23.982962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-11-29 11:30:23.982987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2024-11-29 11:30:23.982990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2024-11-29 11:30:23.983149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-29 11:30:23.984453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-29 11:30:23.985563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-29 11:30:23.986703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22127 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert shape (None, 256, 768)\n"
     ]
    }
   ],
   "source": [
    "# 분류 모델 네트워크 정의\n",
    "import bert\n",
    "\n",
    "input_ids = keras.layers.Input(shape=(MAX_SEQ_LEN,), dtype='int32')\n",
    "\n",
    "# BERT 언어모델 레이어 생성\n",
    "bert_params = bert.params_from_pretrained_ckpt(pretrained_model_dir)\n",
    "l_bert = bert.BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "\n",
    "# 입력레이어와 BERT 레이어 연결\n",
    "bert_output = l_bert(input_ids)\n",
    "print(\"bert shape\", bert_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7f0456fca820>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# BERT 출력 중 [CLS] 토큰 정보를 추출\n",
    "cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
    "\n",
    "# 최종 분류를 위한 레이어\n",
    "outputs = Dense(units=num_classes, activation='softmax')(cls_out)\n",
    "\n",
    "# 모델 빌드\n",
    "model = keras.Model(inputs=input_ids, outputs=outputs)\n",
    "model.build(input_shape=(None, MAX_SEQ_LEN))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading 196 BERT weights from: ./pretrained/model.ckpt-381250 into <bert.model.BertModelLayer object at 0x7f045bdb04f0> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from checkpoint: \n",
      "\tbert/embeddings/LayerNorm/beta/adam_m\n",
      "\tbert/embeddings/LayerNorm/beta/adam_v\n",
      "\tbert/embeddings/LayerNorm/gamma/adam_m\n",
      "\tbert/embeddings/LayerNorm/gamma/adam_v\n",
      "\tbert/embeddings/position_embeddings/adam_m\n",
      "\tbert/embeddings/position_embeddings/adam_v\n",
      "\tbert/embeddings/token_type_embeddings\n",
      "\tbert/embeddings/token_type_embeddings/adam_m\n",
      "\tbert/embeddings/token_type_embeddings/adam_v\n",
      "\tbert/embeddings/word_embeddings/adam_m\n",
      "\tbert/embeddings/word_embeddings/adam_v\n",
      "\tbert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_0/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_0/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_0/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_0/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_0/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_0/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_0/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_0/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_0/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_0/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_0/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_0/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_0/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_0/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_0/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_0/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_0/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_0/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_0/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_0/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_0/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_0/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_0/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_0/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_0/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_0/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_0/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_0/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_1/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_1/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_1/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_1/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_1/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_1/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_1/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_1/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_1/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_1/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_1/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_1/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_1/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_1/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_1/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_1/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_1/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_1/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_1/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_1/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_1/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_1/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_1/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_1/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_1/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_1/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_1/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_1/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_10/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_10/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_10/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_10/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_10/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_10/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_10/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_10/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_10/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_10/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_10/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_10/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_10/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_10/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_10/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_10/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_10/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_10/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_10/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_10/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_10/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_10/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_10/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_10/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_10/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_10/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_10/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_10/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_11/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_11/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_11/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_11/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_11/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_11/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_11/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_11/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_11/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_11/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_11/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_11/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_11/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_11/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_11/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_11/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_11/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_11/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_11/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_11/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_11/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_11/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_11/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_11/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_11/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_11/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_11/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_11/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_2/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_2/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_2/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_2/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_2/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_2/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_2/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_2/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_2/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_2/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_2/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_2/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_2/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_2/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_2/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_2/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_2/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_2/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_2/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_2/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_2/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_2/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_2/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_2/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_2/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_2/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_2/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_2/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_3/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_3/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_3/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_3/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_3/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_3/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_3/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_3/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_3/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_3/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_3/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_3/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_3/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_3/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_3/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_3/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_3/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_3/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_3/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_3/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_3/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_3/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_3/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_3/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_3/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_3/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_3/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_3/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_4/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_4/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_4/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_4/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_4/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_4/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_4/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_4/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_4/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_4/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_4/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_4/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_4/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_4/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_4/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_4/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_4/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_4/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_4/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_4/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_4/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_4/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_4/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_4/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_4/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_4/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_4/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_4/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_5/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_5/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_5/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_5/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_5/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_5/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_5/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_5/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_5/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_5/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_5/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_5/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_5/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_5/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_5/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_5/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_5/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_5/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_5/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_5/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_5/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_5/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_5/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_5/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_5/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_5/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_5/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_5/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_6/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_6/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_6/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_6/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_6/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_6/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_6/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_6/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_6/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_6/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_6/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_6/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_6/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_6/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_6/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_6/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_6/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_6/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_6/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_6/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_6/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_6/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_6/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_6/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_6/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_6/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_6/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_6/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_7/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_7/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_7/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_7/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_7/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_7/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_7/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_7/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_7/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_7/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_7/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_7/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_7/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_7/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_7/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_7/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_7/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_7/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_7/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_7/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_7/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_7/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_7/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_7/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_7/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_7/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_7/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_7/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_8/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_8/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_8/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_8/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_8/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_8/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_8/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_8/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_8/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_8/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_8/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_8/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_8/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_8/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_8/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_8/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_8/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_8/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_8/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_8/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_8/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_8/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_8/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_8/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_8/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_8/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_8/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_8/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_9/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_9/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_9/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_9/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_9/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_9/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_9/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_9/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_9/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_9/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_9/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_9/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_9/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_9/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_9/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_9/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_9/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_9/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_9/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_9/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_9/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_9/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_9/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_9/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_9/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_9/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_9/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_9/output/dense/kernel/adam_v\n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/bias/adam_m\n",
      "\tbert/pooler/dense/bias/adam_v\n",
      "\tbert/pooler/dense/kernel\n",
      "\tbert/pooler/dense/kernel/adam_m\n",
      "\tbert/pooler/dense/kernel/adam_v\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/output_bias/adam_m\n",
      "\tcls/predictions/output_bias/adam_v\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/beta/adam_m\n",
      "\tcls/predictions/transform/LayerNorm/beta/adam_v\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/LayerNorm/gamma/adam_m\n",
      "\tcls/predictions/transform/LayerNorm/gamma/adam_v\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/bias/adam_m\n",
      "\tcls/predictions/transform/dense/bias/adam_v\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "\tcls/predictions/transform/dense/kernel/adam_m\n",
      "\tcls/predictions/transform/dense/kernel/adam_v\n",
      "\tcls/seq_relationship/output_bias\n",
      "\tcls/seq_relationship/output_bias/adam_m\n",
      "\tcls/seq_relationship/output_bias/adam_v\n",
      "\tcls/seq_relationship/output_weights\n",
      "\tcls/seq_relationship/output_weights/adam_m\n",
      "\tcls/seq_relationship/output_weights/adam_v\n",
      "\tcurrent_loss_scale\n",
      "\tglobal_step\n",
      "\tgood_steps\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "bert (BertModelLayer)        (None, 256, 768)          101884416 \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 2307      \n",
      "=================================================================\n",
      "Total params: 101,886,723\n",
      "Trainable params: 101,886,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# BERT 언어모델의 초기 가중치 로드\n",
    "bert.load_stock_weights(l_bert, checkpoint_path)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LR),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 11:30:25.532085: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2024-11-29 11:30:25.532295: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3187200000 Hz\n",
      "2024-11-29 11:30:30.038034: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/271 [..............................] - ETA: 22:20 - loss: 1.6374 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 11:30:30.323175: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-11-29 11:30:30.323217: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271/271 [==============================] - 54s 180ms/step - loss: 0.4714 - accuracy: 0.8155 - val_loss: 0.2874 - val_accuracy: 0.8880\n",
      "Epoch 2/5\n",
      "271/271 [==============================] - 48s 177ms/step - loss: 0.2336 - accuracy: 0.9117 - val_loss: 0.3069 - val_accuracy: 0.8880\n",
      "Epoch 3/5\n",
      "271/271 [==============================] - 48s 177ms/step - loss: 0.1172 - accuracy: 0.9575 - val_loss: 0.2777 - val_accuracy: 0.8921\n",
      "Epoch 4/5\n",
      "271/271 [==============================] - 48s 177ms/step - loss: 0.0465 - accuracy: 0.9857 - val_loss: 0.4117 - val_accuracy: 0.9212\n",
      "Epoch 5/5\n",
      "271/271 [==============================] - 48s 177ms/step - loss: 0.0518 - accuracy: 0.9843 - val_loss: 0.3237 - val_accuracy: 0.9170\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 시작\n",
    "history = model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(val_x, val_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 3s 158ms/step - loss: 0.5266 - accuracy: 0.8721\n",
      "\n",
      "===> 평가 결과:\n",
      "테스트 손실: 0.5266\n",
      "테스트 정확도: 0.8721\n",
      "\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        G06F     0.7170    0.7677    0.7415        99\n",
      "        G06Q     0.9226    0.9308    0.9267       448\n",
      "        G16H     0.7273    0.5818    0.6465        55\n",
      "\n",
      "    accuracy                         0.8721       602\n",
      "   macro avg     0.7889    0.7601    0.7715       602\n",
      "weighted avg     0.8709    0.8721    0.8706       602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장 및 테스트 데이터로 평가\n",
    "model.save(save_model_path)\n",
    "eval_result = model.evaluate(test_x, test_y)\n",
    "\n",
    "print('\\n===> 평가 결과:')\n",
    "print(\"테스트 손실: %.4f\" % (eval_result[0]))\n",
    "print(\"테스트 정확도: %.4f\" % (eval_result[1]))\n",
    "\n",
    "# 분류 보고서 생성\n",
    "y_pred_probs = model.predict(test_x)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(test_y, axis=1)\n",
    "\n",
    "# 분류 리포트 출력\n",
    "print('\\n분류 리포트:')\n",
    "print(classification_report(y_true, y_pred,\n",
    "      target_names=label_encoder.classes_, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "korpatbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
