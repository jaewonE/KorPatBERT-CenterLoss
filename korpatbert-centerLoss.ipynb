{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 21:56:39.681170: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "/home/billy/anaconda3/envs/korpatbert/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.5.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.5.0\n",
      "Thu Nov 28 21:56:40 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A5000               Off |   00000000:01:00.0 Off |                  Off |\n",
      "| 30%   29C    P0             76W /  230W |     239MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1336      G   /usr/lib/xorg/Xorg                            215MiB |\n",
      "|    0   N/A  N/A      1544      G   /usr/bin/gnome-shell                            8MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow_addons as tfa  # AdamW 옵티마이저 사용\n",
    "from sklearn.utils import class_weight\n",
    "import re\n",
    "\n",
    "# Tensorflow 버전과 GPU 사용 여부 확인\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_excel(data_path,\n",
    "                       usecols=['발명의 명칭', '요약', '메인IPC2', '대표청구항'])\n",
    "    df['input'] = df.apply(\n",
    "        lambda row: f\"{row['발명의 명칭']}\\n\\n{row['요약']}\", axis=1)\n",
    "    df = df.drop(columns=['발명의 명칭', '요약', '대표청구항'])\n",
    "    df.columns = ['메인IPC2', '대표청구항']\n",
    "    return df\n",
    "\n",
    "\n",
    "# Paths to data files and model files\n",
    "xlsx_path_train = '/home/billy/rd/dataset/DS학술제-모델링경진대회_Train.xlsx'\n",
    "xlsx_path_test = '/home/billy/rd/dataset/DS학술제-모델링경진대회_Valid.xlsx'\n",
    "\n",
    "vocab_path = \"./pretrained/korpat_vocab.txt\"\n",
    "checkpoint_path = \"./pretrained/model.ckpt-381250\"\n",
    "pretrained_model_dir = \"./pretrained/\"\n",
    "save_model_path = \"./korpat_bert_centerloss_model.h5\"\n",
    "\n",
    "MAX_SEQ_LEN = 256\n",
    "BATCH_SIZE = 8\n",
    "LR = 0.00003\n",
    "EPOCHS = 5\n",
    "lambda_c = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 인코딩 결과:\n",
      "G06F: 0\n",
      "G06Q: 1\n",
      "G16H: 2\n"
     ]
    }
   ],
   "source": [
    "from korpat_tokenizer import Tokenizer\n",
    "tokenizer = Tokenizer(vocab_path=vocab_path, cased=True)\n",
    "\n",
    "# 엑셀 파일에서 데이터 로드\n",
    "df_train = load_data(xlsx_path_train)\n",
    "df_test = load_data(xlsx_path_test)\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['label'] = label_encoder.fit_transform(df_train['메인IPC2'])\n",
    "\n",
    "# 레이블 인코딩 결과 출력\n",
    "print(\"레이블 인코딩 결과:\")\n",
    "for label, index in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)):\n",
    "    print(f\"{label}: {index}\")\n",
    "\n",
    "# 테스트 데이터에서 보이지 않는 레이블 처리\n",
    "unseen_labels = set(df_test['메인IPC2']) - set(label_encoder.classes_)\n",
    "if unseen_labels:\n",
    "    print(\"주의: 테스트 데이터셋에 훈련 데이터셋에 없는 레이블이 있습니다. 해당 샘플을 제거합니다.\")\n",
    "    print(f\"제거될 레이블: {unseen_labels}\")\n",
    "    df_test = df_test[~df_test['메인IPC2'].isin(\n",
    "        unseen_labels)].reset_index(drop=True)\n",
    "\n",
    "# 테스트 레이블 변환\n",
    "df_test['label'] = label_encoder.transform(df_test['메인IPC2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 클래스 수: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 학습과 검증 데이터셋을 나누기\n",
    "train_texts_full = df_train['대표청구항']\n",
    "train_labels_full = df_train['label']\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts_full, train_labels_full, test_size=0.1, random_state=42, stratify=train_labels_full\n",
    ")\n",
    "\n",
    "# 테스트 데이터셋\n",
    "test_texts = df_test['대표청구항']\n",
    "test_labels = df_test['label']\n",
    "\n",
    "# 학습, 검증, 테스트 데이터셋을 위한 DataFrame 생성\n",
    "train_data = pd.DataFrame({'sentence': train_texts, 'label': train_labels})\n",
    "val_data = pd.DataFrame({'sentence': val_texts, 'label': val_labels})\n",
    "test_data = pd.DataFrame({'sentence': test_texts, 'label': test_labels})\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(\"레이블 클래스 수:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> 학습데이터 전처리 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "데이터 전처리 진행중: 2163it [00:06, 331.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===> 검증데이터 전처리 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "데이터 전처리 진행중: 241it [00:00, 360.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===> 테스트데이터 전처리 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "데이터 전처리 진행중: 602it [00:01, 326.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 함수\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def preprocessing_dataset(dataset, num_classes):\n",
    "    tokens, indices, labels = [], [], []\n",
    "\n",
    "    for label, sentence in tqdm(zip(dataset['label'], dataset['sentence']), desc=\"데이터 전처리 진행중\"):\n",
    "        # 간단한 데이터 정규화\n",
    "        sentence = re.sub(r\"[^가-힣a-zA-Z0-9\\s]\", \"\", sentence)  # 특수문자 제거\n",
    "        sentence = re.sub(r\"\\s+\", \" \", sentence).strip()        # 여분의 공백 제거\n",
    "        tokens.append(tokenizer.tokenize(sentence))\n",
    "        ids, _ = tokenizer.encode(sentence, max_len=MAX_SEQ_LEN)\n",
    "        indices.append(ids)\n",
    "        # 레이블을 원-핫 인코딩 벡터로 변환\n",
    "        labels.append(to_categorical(label, num_classes=num_classes))\n",
    "\n",
    "    x_data = np.array(indices)\n",
    "    y_data = np.array(labels)\n",
    "    return tokens, x_data, y_data\n",
    "\n",
    "\n",
    "print(\"===> 학습데이터 전처리 시작\")\n",
    "train_tokens, train_x, train_y = preprocessing_dataset(train_data, num_classes)\n",
    "\n",
    "print(\"\\n===> 검증데이터 전처리 시작\")\n",
    "val_tokens, val_x, val_y = preprocessing_dataset(val_data, num_classes)\n",
    "\n",
    "print(\"\\n===> 테스트데이터 전처리 시작\")\n",
    "test_tokens, test_x, test_y = preprocessing_dataset(test_data, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 21:56:50.771882: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2024-11-28 21:56:50.874713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-28 21:56:50.877899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA RTX A5000 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 64 deviceMemorySize: 23.58GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2024-11-28 21:56:50.877911: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-11-28 21:56:50.880466: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2024-11-28 21:56:50.880506: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-11-28 21:56:50.893703: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2024-11-28 21:56:50.893848: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2024-11-28 21:56:50.910944: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2024-11-28 21:56:50.911419: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-11-28 21:56:50.911514: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-11-28 21:56:50.911581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-28 21:56:50.914571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-28 21:56:50.917239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2024-11-28 21:56:50.917687: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-28 21:56:50.918757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-28 21:56:50.921468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA RTX A5000 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 64 deviceMemorySize: 23.58GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2024-11-28 21:56:50.921500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-28 21:56:50.924111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-28 21:56:50.926793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2024-11-28 21:56:50.926807: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-11-28 21:56:51.160902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-11-28 21:56:51.160927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2024-11-28 21:56:51.160931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2024-11-28 21:56:51.161124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-28 21:56:51.162355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-28 21:56:51.163412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-28 21:56:51.164459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22127 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert shape (None, 256, 768)\n",
      "Done loading 196 BERT weights from: ./pretrained/model.ckpt-381250 into <bert.model.BertModelLayer object at 0x700bddaf67c0> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from checkpoint: \n",
      "\tbert/embeddings/LayerNorm/beta/adam_m\n",
      "\tbert/embeddings/LayerNorm/beta/adam_v\n",
      "\tbert/embeddings/LayerNorm/gamma/adam_m\n",
      "\tbert/embeddings/LayerNorm/gamma/adam_v\n",
      "\tbert/embeddings/position_embeddings/adam_m\n",
      "\tbert/embeddings/position_embeddings/adam_v\n",
      "\tbert/embeddings/token_type_embeddings\n",
      "\tbert/embeddings/token_type_embeddings/adam_m\n",
      "\tbert/embeddings/token_type_embeddings/adam_v\n",
      "\tbert/embeddings/word_embeddings/adam_m\n",
      "\tbert/embeddings/word_embeddings/adam_v\n",
      "\tbert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_0/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_0/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_0/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_0/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_0/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_0/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_0/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_0/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_0/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_0/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_0/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_0/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_0/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_0/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_0/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_0/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_0/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_0/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_0/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_0/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_0/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_0/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_0/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_0/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_0/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_0/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_0/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_0/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_1/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_1/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_1/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_1/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_1/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_1/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_1/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_1/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_1/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_1/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_1/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_1/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_1/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_1/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_1/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_1/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_1/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_1/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_1/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_1/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_1/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_1/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_1/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_1/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_1/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_1/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_1/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_1/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_10/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_10/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_10/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_10/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_10/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_10/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_10/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_10/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_10/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_10/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_10/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_10/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_10/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_10/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_10/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_10/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_10/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_10/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_10/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_10/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_10/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_10/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_10/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_10/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_10/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_10/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_10/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_10/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_11/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_11/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_11/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_11/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_11/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_11/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_11/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_11/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_11/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_11/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_11/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_11/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_11/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_11/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_11/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_11/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_11/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_11/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_11/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_11/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_11/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_11/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_11/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_11/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_11/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_11/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_11/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_11/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_2/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_2/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_2/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_2/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_2/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_2/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_2/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_2/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_2/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_2/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_2/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_2/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_2/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_2/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_2/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_2/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_2/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_2/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_2/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_2/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_2/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_2/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_2/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_2/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_2/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_2/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_2/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_2/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_3/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_3/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_3/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_3/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_3/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_3/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_3/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_3/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_3/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_3/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_3/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_3/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_3/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_3/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_3/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_3/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_3/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_3/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_3/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_3/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_3/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_3/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_3/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_3/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_3/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_3/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_3/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_3/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_4/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_4/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_4/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_4/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_4/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_4/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_4/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_4/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_4/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_4/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_4/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_4/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_4/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_4/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_4/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_4/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_4/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_4/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_4/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_4/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_4/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_4/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_4/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_4/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_4/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_4/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_4/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_4/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_5/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_5/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_5/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_5/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_5/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_5/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_5/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_5/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_5/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_5/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_5/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_5/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_5/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_5/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_5/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_5/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_5/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_5/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_5/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_5/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_5/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_5/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_5/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_5/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_5/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_5/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_5/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_5/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_6/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_6/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_6/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_6/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_6/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_6/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_6/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_6/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_6/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_6/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_6/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_6/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_6/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_6/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_6/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_6/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_6/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_6/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_6/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_6/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_6/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_6/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_6/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_6/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_6/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_6/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_6/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_6/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_7/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_7/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_7/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_7/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_7/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_7/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_7/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_7/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_7/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_7/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_7/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_7/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_7/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_7/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_7/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_7/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_7/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_7/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_7/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_7/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_7/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_7/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_7/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_7/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_7/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_7/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_7/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_7/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_8/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_8/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_8/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_8/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_8/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_8/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_8/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_8/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_8/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_8/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_8/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_8/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_8/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_8/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_8/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_8/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_8/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_8/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_8/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_8/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_8/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_8/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_8/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_8/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_8/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_8/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_8/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_8/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_9/attention/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_9/attention/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_9/attention/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_9/attention/output/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_9/attention/self/key/bias/adam_m\n",
      "\tbert/encoder/layer_9/attention/self/key/bias/adam_v\n",
      "\tbert/encoder/layer_9/attention/self/key/kernel/adam_m\n",
      "\tbert/encoder/layer_9/attention/self/key/kernel/adam_v\n",
      "\tbert/encoder/layer_9/attention/self/query/bias/adam_m\n",
      "\tbert/encoder/layer_9/attention/self/query/bias/adam_v\n",
      "\tbert/encoder/layer_9/attention/self/query/kernel/adam_m\n",
      "\tbert/encoder/layer_9/attention/self/query/kernel/adam_v\n",
      "\tbert/encoder/layer_9/attention/self/value/bias/adam_m\n",
      "\tbert/encoder/layer_9/attention/self/value/bias/adam_v\n",
      "\tbert/encoder/layer_9/attention/self/value/kernel/adam_m\n",
      "\tbert/encoder/layer_9/attention/self/value/kernel/adam_v\n",
      "\tbert/encoder/layer_9/intermediate/dense/bias/adam_m\n",
      "\tbert/encoder/layer_9/intermediate/dense/bias/adam_v\n",
      "\tbert/encoder/layer_9/intermediate/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_9/intermediate/dense/kernel/adam_v\n",
      "\tbert/encoder/layer_9/output/LayerNorm/beta/adam_m\n",
      "\tbert/encoder/layer_9/output/LayerNorm/beta/adam_v\n",
      "\tbert/encoder/layer_9/output/LayerNorm/gamma/adam_m\n",
      "\tbert/encoder/layer_9/output/LayerNorm/gamma/adam_v\n",
      "\tbert/encoder/layer_9/output/dense/bias/adam_m\n",
      "\tbert/encoder/layer_9/output/dense/bias/adam_v\n",
      "\tbert/encoder/layer_9/output/dense/kernel/adam_m\n",
      "\tbert/encoder/layer_9/output/dense/kernel/adam_v\n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/bias/adam_m\n",
      "\tbert/pooler/dense/bias/adam_v\n",
      "\tbert/pooler/dense/kernel\n",
      "\tbert/pooler/dense/kernel/adam_m\n",
      "\tbert/pooler/dense/kernel/adam_v\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/output_bias/adam_m\n",
      "\tcls/predictions/output_bias/adam_v\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/beta/adam_m\n",
      "\tcls/predictions/transform/LayerNorm/beta/adam_v\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/LayerNorm/gamma/adam_m\n",
      "\tcls/predictions/transform/LayerNorm/gamma/adam_v\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/bias/adam_m\n",
      "\tcls/predictions/transform/dense/bias/adam_v\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "\tcls/predictions/transform/dense/kernel/adam_m\n",
      "\tcls/predictions/transform/dense/kernel/adam_v\n",
      "\tcls/seq_relationship/output_bias\n",
      "\tcls/seq_relationship/output_bias/adam_m\n",
      "\tcls/seq_relationship/output_bias/adam_v\n",
      "\tcls/seq_relationship/output_weights\n",
      "\tcls/seq_relationship/output_weights/adam_m\n",
      "\tcls/seq_relationship/output_weights/adam_v\n",
      "\tcurrent_loss_scale\n",
      "\tglobal_step\n",
      "\tgood_steps\n"
     ]
    }
   ],
   "source": [
    "import bert\n",
    "from bert import BertModelLayer\n",
    "\n",
    "\n",
    "class ClsToken(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        return inputs[:, 0, :]\n",
    "\n",
    "\n",
    "# 입력 레이어\n",
    "input_ids = keras.layers.Input(\n",
    "    shape=(MAX_SEQ_LEN,), dtype='int32', name='input_ids')\n",
    "\n",
    "# BERT 레이어\n",
    "bert_params = bert.params_from_pretrained_ckpt(pretrained_model_dir)\n",
    "l_bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "\n",
    "# BERT 출력\n",
    "bert_output = l_bert(input_ids)\n",
    "print(\"bert shape\", bert_output.shape)\n",
    "\n",
    "# CLS 토큰\n",
    "cls_out = ClsToken(name='cls_token')(bert_output)\n",
    "\n",
    "# 드롭아웃 추가\n",
    "cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
    "\n",
    "# 출력 레이어\n",
    "outputs = Dense(units=num_classes, activation='softmax',\n",
    "                name='output')(cls_out)\n",
    "\n",
    "# 로짓과 특징을 출력으로 가지는 모델 정의\n",
    "model = keras.Model(inputs=input_ids, outputs=[outputs, cls_out])\n",
    "model.build(input_shape=(None, MAX_SEQ_LEN))\n",
    "\n",
    "# KorPatBERT 체크포인트에서 직접 BERT 가중치 로드\n",
    "bert.load_stock_weights(l_bert, checkpoint_path)\n",
    "\n",
    "\n",
    "# CenterLoss 레이어 정의 (정규화로 수정됨)\n",
    "class CenterLoss(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_classes, feat_dim, **kwargs):\n",
    "        super(CenterLoss, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.feat_dim = feat_dim\n",
    "        # 중심 초기화 및 정규화\n",
    "        initializer = tf.keras.initializers.RandomUniform(minval=-1, maxval=1)\n",
    "        centers = initializer(shape=(num_classes, feat_dim))\n",
    "        self.centers = tf.Variable(tf.nn.l2_normalize(\n",
    "            centers, axis=1), trainable=True, name='centers')\n",
    "\n",
    "    def call(self, features, labels):\n",
    "        labels = tf.cast(labels, tf.int32)\n",
    "        # 특징 정규화\n",
    "        normalized_features = tf.nn.l2_normalize(features, axis=1)\n",
    "        # 중심 정규화 (정규화 상태 유지)\n",
    "        normalized_centers = tf.nn.l2_normalize(self.centers, axis=1)\n",
    "        centers_batch = tf.gather(normalized_centers, labels)\n",
    "        # 특징과 중심의 차이 계산\n",
    "        diff = normalized_features - centers_batch\n",
    "        # 차이의 제곱 L2 노름 계산 (샘플별)\n",
    "        per_sample_loss = tf.reduce_sum(tf.square(diff), axis=1)\n",
    "        # 배치 전체의 평균 손실 계산\n",
    "        loss = tf.reduce_mean(per_sample_loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "# CenterLoss 레이어 인스턴스화\n",
    "hidden_size = cls_out.shape[-1]\n",
    "center_loss_layer = CenterLoss(num_classes=num_classes, feat_dim=hidden_size)\n",
    "\n",
    "# 옵티마이저 정의\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "    learning_rate=LR, weight_decay=1e-4)  # AdamW 사용\n",
    "\n",
    "\n",
    "# 학습률 스케줄러 적용\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < EPOCHS * 0.6:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "# 교차 엔트로피를 위한 손실 함수 정의\n",
    "loss_fn = keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "에폭 1/5\n",
      "------------------------------\n",
      "WARNING:tensorflow:From /home/billy/anaconda3/envs/korpatbert/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 21:56:55.147650: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2024-11-28 21:56:55.169211: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3187200000 Hz\n",
      "2024-11-28 21:56:55.851365: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2024-11-28 21:56:56.138419: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-11-28 21:56:56.138454: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 손실 총합 0.6252, 정확도 0.7748\n",
      "검증 손실 총합 0.2680, 정확도 0.9046\n",
      "현재 학습률: 0.000030\n",
      "\n",
      "에폭 2/5\n",
      "------------------------------\n",
      "훈련 손실 총합 0.3270, 정확도 0.8803\n",
      "검증 손실 총합 0.2434, 정확도 0.9129\n",
      "현재 학습률: 0.000030\n",
      "\n",
      "에폭 3/5\n",
      "------------------------------\n",
      "훈련 손실 총합 0.2289, 정확도 0.9168\n",
      "검증 손실 총합 0.1771, 정확도 0.9378\n",
      "현재 학습률: 0.000030\n",
      "\n",
      "에폭 4/5\n",
      "------------------------------\n",
      "훈련 손실 총합 0.1482, 정확도 0.9482\n",
      "검증 손실 총합 0.1748, 정확도 0.9378\n",
      "현재 학습률: 0.000027\n",
      "\n",
      "에폭 5/5\n",
      "------------------------------\n",
      "훈련 손실 총합 0.1186, 정확도 0.9593\n",
      "검증 손실 총합 0.2560, 정확도 0.9212\n",
      "현재 학습률: 0.000025\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# 학습 내용 정의\n",
    "@tf.function\n",
    "def train_step(x_batch, y_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits, features = model(x_batch, training=True)\n",
    "        # 교차 엔트로피 손실 계산\n",
    "        loss_ce = loss_fn(y_batch, logits)\n",
    "        # 레이블을 인덱스로 변환\n",
    "        labels = tf.argmax(y_batch, axis=1)\n",
    "        # 센터 손실 계산\n",
    "        loss_center = center_loss_layer(features, labels)\n",
    "        # 전체 손실\n",
    "        loss = loss_ce + lambda_c * loss_center\n",
    "    # 그래디언트 계산\n",
    "    gradients = tape.gradient(\n",
    "        loss, model.trainable_variables + [center_loss_layer.centers])\n",
    "    # 파라미터 업데이트\n",
    "    optimizer.apply_gradients(\n",
    "        zip(gradients, model.trainable_variables + [center_loss_layer.centers]))\n",
    "    return loss, loss_ce, loss_center, logits\n",
    "\n",
    "\n",
    "# 검증 내용 정의\n",
    "@tf.function\n",
    "def val_step(x_batch, y_batch):\n",
    "    logits, features = model(x_batch, training=False)\n",
    "    loss_ce = loss_fn(y_batch, logits)\n",
    "    labels = tf.argmax(y_batch, axis=1)\n",
    "    loss_center = center_loss_layer(features, labels)\n",
    "    loss = loss_ce + lambda_c * loss_center\n",
    "    return loss, logits\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\n에폭 {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 30)\n",
    "    # 학습 루프\n",
    "    total_loss = 0.\n",
    "    total_loss_ce = 0.\n",
    "    total_loss_center = 0.\n",
    "    num_batches = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        loss, loss_ce, loss_center, logits = train_step(\n",
    "            x_batch_train, y_batch_train)\n",
    "        # 메트릭 업데이트\n",
    "        total_loss += loss.numpy()\n",
    "        total_loss_ce += loss_ce.numpy()\n",
    "        total_loss_center += loss_center.numpy()\n",
    "        num_batches += 1\n",
    "        y_pred = tf.argmax(logits, axis=1)\n",
    "        y_true = tf.argmax(y_batch_train, axis=1)\n",
    "        correct_predictions += tf.reduce_sum(\n",
    "            tf.cast(y_pred == y_true, tf.float32)).numpy()\n",
    "    train_acc = correct_predictions / len(train_x)\n",
    "    train_loss = total_loss / num_batches\n",
    "    print(f'훈련 손실 총합 {train_loss:.4f}, 정확도 {train_acc:.4f}')\n",
    "\n",
    "    # 검증 루프\n",
    "    total_val_loss = 0.\n",
    "    num_val_batches = 0\n",
    "    val_correct_predictions = 0\n",
    "    for val_step_idx, (x_batch_val, y_batch_val) in enumerate(val_dataset):\n",
    "        loss, logits = val_step(x_batch_val, y_batch_val)\n",
    "        total_val_loss += loss.numpy()\n",
    "        num_val_batches += 1\n",
    "        y_pred = tf.argmax(logits, axis=1)\n",
    "        y_true = tf.argmax(y_batch_val, axis=1)\n",
    "        val_correct_predictions += tf.reduce_sum(\n",
    "            tf.cast(y_pred == y_true, tf.float32)).numpy()\n",
    "    val_acc = val_correct_predictions / len(val_x)\n",
    "    val_loss = total_val_loss / num_val_batches\n",
    "    print(f'검증 손실 총합 {val_loss:.4f}, 정확도 {val_acc:.4f}')\n",
    "\n",
    "    # 학습률 스케줄러 업데이트\n",
    "    lr = scheduler(epoch, optimizer.lr)\n",
    "    optimizer.lr.assign(lr)\n",
    "    print(f'현재 학습률: {optimizer.lr.numpy():.6f}')\n",
    "\n",
    "\n",
    "# 학습된 모델 저장\n",
    "model.save(save_model_path)\n",
    "\n",
    "# 메모리 내 모델 삭제\n",
    "# 저장된 모델을 가져와서 테스트 데이터셋을 테스트 하기 위함.\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "\n",
      "테스트 정확도: 0.9103\n",
      "\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        G06F     0.8588    0.7374    0.7935        99\n",
      "        G06Q     0.9427    0.9554    0.9490       448\n",
      "        G16H     0.7460    0.8545    0.7966        55\n",
      "\n",
      "    accuracy                         0.9103       602\n",
      "   macro avg     0.8492    0.8491    0.8464       602\n",
      "weighted avg     0.9110    0.9103    0.9095       602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 저장된 파일에서 학습된 모델 불러오기\n",
    "model = tf.keras.models.load_model(\n",
    "    save_model_path,\n",
    "    custom_objects={'BertModelLayer': BertModelLayer, 'ClsToken': ClsToken}\n",
    ")\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "test_correct_predictions = 0\n",
    "y_preds = []\n",
    "y_trues = []\n",
    "for test_step_idx, (x_batch_test, y_batch_test) in enumerate(test_dataset):\n",
    "    logits, features = model(x_batch_test, training=False)\n",
    "    y_pred = tf.argmax(logits, axis=1)\n",
    "    y_true = tf.argmax(y_batch_test, axis=1)\n",
    "    test_correct_predictions += tf.reduce_sum(\n",
    "        tf.cast(y_pred == y_true, tf.float32)).numpy()\n",
    "    y_preds.extend(y_pred.numpy())\n",
    "    y_trues.extend(y_true.numpy())\n",
    "\n",
    "test_acc = test_correct_predictions / len(test_x)\n",
    "print(f'\\n테스트 정확도: {test_acc:.4f}')\n",
    "\n",
    "# 분류 리포트 생성\n",
    "print('\\n분류 리포트:')\n",
    "print(classification_report(y_trues, y_preds,\n",
    "      target_names=label_encoder.classes_, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "korpatbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
